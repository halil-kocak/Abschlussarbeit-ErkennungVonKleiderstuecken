\documentclass[12pt]{scrreprt}

\linespread{1.25}

\usepackage[ngerman]{babel}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage[a4paper,lmargin={4 cm},rmargin={2 cm},tmargin={2.5 cm},bmargin = {2.5 cm}]{geometry}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{pdfpages}
\usepackage{hyperref}

\begin{document}
	
\begin{titlepage}
	
\includepdf[scale=1]{TitelblattBA}
	
\end{titlepage}	

\newpage
\tableofcontents
\newpage

\listoffigures
\addcontentsline{toc}{chapter}{Abbildungsverzeichnis}
\newpage

\listoftables
\addcontentsline{toc}{chapter}{Tabellenverzeichnis}
\newpage

\chapter{Einleitung}
Es war schon immer die Frage ob Maschinen jemals selbst, anhand vorhandenen Informationen, Entscheidungen treffen oder wie ein Mensch Regeln aus bestimmten Prozessen extrahieren können \cite{Chollet2018}(K.1.1.1). Diese Fragestellung ist vor allem in der heutigen Zeit, in der das Thema Digitalisierung voran getrieben wird, von großer Bedeutung. Auch setzen Unternehmen immer mehr auf Techniken aus dem Bereich des Maschinellen Lernens (ML) und verwenden diese um ihre Prozesse zu digitalisieren und somit zu optimieren. Es existieren verschiedene ML-Techniken, wie zum Beispiel die Klassifikation, Regression oder Deep Learning. Letzteres steht im Mittelpunkt vieler Anwendungsszenarien. Anwendungsfelder für Deep Learning sind vor allem, Bild- und Videoanalyse, sowie die Sprachverarbeitung. Diese werden in verschiedenen Branchen, wie zum Beispiel der Medizin, der Automobilindustrie oder im Kundendienst eingesetzt \cite{FraunhoferGesellschaft2018}. Auch im Bereich Online-Retail finden ML-Techniken einen relevanten Einsatz. Im Rahmen dieser Bachelor-Arbeit liegt der Fokus vor allem in diesem Bereich und wie die Bildanalyse hier unterstützen kann. Im Bereich Online-Retail können zum Beispiel von Kunden bestellte Artikel zurück gesendet werden. Diese Artikel müssen dann wieder richtig gekennzeichnet und neu einsortiert werden. Dieser manueller Prozess kann durch den Einsatz von einer Bildanalyse bzw. Bilderkennung optimiert und automatisiert werden. Dadurch können zum Beispiel wieder eingegangene Waren automatisch erkannt, entsprechend gelabelt und für den erneuten Verkauf vorbereitet werden. Diese Problemstellung wird in einem späteren Abschnitt der Arbeit, im Rahmen des Business Understanding des CRISP-DM Standards (Cross Industry Standard Process for Data Mining), näher definiert.\\
	\\
Diese Bachelor-Arbeit beinhaltet die Erkennung von Objekten auf Bildern durch den Einsatz von Künstlicher Intelligenz. Dabei wird die Disziplin Deep Learning unter Einsatz von Convutional Neural Network verwendet. Um diese zu verstehen werden zuerst allgemeine Informationen zur Künstlichen Intelligenz und dessen Bestandteile und Algorithmen benötigt. Zu Beginn ist es wichtig zu wissen, welche Probleme die Künstliche Intelligenz lösen kann und welche Bestandteile für diese Arbeit benötigt werden. In diesem Zusammenhang wird das Verfahren Convutional Neural Network behandelt, welches zu den Deep Learning Methoden gehört und eine Teilmenge der Maschinellen Lernalgorithmen bildet. Außerdem wird im Rahmen dieser Arbeit das CRIPS-DM Modell vorgestellt und verwendet, welches als Standard für Data Mining Modelle definiert wurde.\\
\\
Der Aufbau der Arbeit beginnt mit der Einführung in das Maschinelle Lernen und allen wichtigen Komponenten, wie zum Beispiel die in der Arbeit eingesetzten Verfahren und wichtige Evaluationsmetriken für die Bewertung der Experimente. Danach erfolgt ein Einblick in das CRISP-DM Modell, welches für das bearbeitete Data Mining Experiment als Vorgehensmuster eingesetzt wird. Im Anschluss folgen die Experimente. In diesem Abschnitt wird das CRISP-DM Modell angewendet und die einzelnen Phasen des Modells bearbeitet. Hier wird unter anderem die Problemstellung detailliert erläutert, der verwendete Datensatz beschrieben und die implementierten Modelle erklärt und evaluiert. Als letztes folgt eine Zusammenfassung der gesamten Arbeit und ein möglicher Ausblick für die Fortsetzung dessen.
	
\newpage
\chapter{Maschinelles Lernen}
	
Maschinelles Lernen stellt ein Teilgebiet der Künstlichen Intelligenz dar. Dabei werden durch den Einsatz von Maschinen ein Verhalten aus den Daten extrahiert, wodurch die Maschine selbst Lernen kann. Dies Geschieht unter Verwendung verschiedener Techniken und Algorithmen. Während der Lernphase versucht die Maschine, Regelmäßigkeiten aus den Daten zu erkennen und diese zu verallgemeinern. Nachdem die Lernphase beendet ist, kann die Maschine eine Vorhersage aus den aktuellen Daten treffen \cite{Frochte2021}(S.2-3).\\
\begin{figure}[h!]
	\centering
	\includegraphics[width=12cm, height=5cm]{Abbildung_MaschinellesLernen_1.jpg}
	\caption{Maschinelles Lernen vs. Klassische Programmierung \cite{Chollet2018}(K.1.1.2}
	\label{fig:fig1}
\end{figure}
\\
In der Abbildung \ref{fig:fig1}, ist der Unterschied zwischen der Klassischen Programmierung und den Maschinellen Lernalgorithmen zu sehen. Bei der Klassischen Programmierung werden Regeln definiert und implementiert. Anhand dieser Regeln werden die Daten verarbeitet, die dann zu einer Antwort führen. Anders ist es aber bei den Maschinellen Lernalgorithmen. Hier werden Daten und dessen Antworten als Eingabedaten betrachtet, wodurch die Maschine für sich die Regeln definiert \cite{Chollet2018}(Kapitel 1). Dazu haben alle Maschinelle Lernverfahren zwei Phasen. Die erste Phase ist die Lernphase, in der es lernt, aus den Eingabedaten ein Muster zu extrahieren. Nachdem diese Phase beendet ist, wird die Anwendungsphase gestartet. Diese Phase wird sowohl für die Evaluation des Künstliche Intelligenz als auch für die Anwendung genutzt. Es ist zu beachten das die Künstliche Intelligenz auch in der Anwendungsphase lernen kann  \cite{Chollet2018}(Kapitel 2.1). 
	\\
	\\
Um Entscheidungen zu treffen, werden Eingabedaten benötigt, die der Maschine die nötigen Informationen liefern. Die Eingabedaten beinhalten auch die Lösung des Problems und somit auch den Wert, der von der Maschine vorhergesagt werden soll. Damit die Maschine nach Effizienz bewertet werden kann, ist eine Messung der Algorithmen erforderlich \cite{Chollet2018}(Kapitel 1.1.3).
	\\
	\\
Für die Lösungen der Probleme werden verschiedentliche Maschinelle Lernalgorithmen verwenden. Die Entscheidung welches benutzt werden soll hängt von den Eingabedaten und dem Ziel ab. Im Rahmen dieser Arbeit liegt der Fokus auf dem Convutional Neural Network Verfahren, welches zur Kategorie des überwachten Lernens gehört \cite{Luber2019}.
	
\section{Überwachtes Lernen}
Das überwachte Lernen gehört zu den Lernverfahren des maschinellen Lernens und umfasst die Klassifikation und Regression. Bei einem überwachten Lernen werden Eingabedaten, die Beispiele beinhalten, einem bekannten Zielwert zugeordnet. Dadurch sind die Zielwerte bekannt und somit können die Fehler, bei einer falschen Klassifikation, während dem Lernprozess entdeckt werden \cite{Chollet2018}(K.4.1.2).
	
\section{Klassifizierung}
	
In diesem Abschnitt wird das Ziel der Klassifizierung beschrieben. Dabei handelt es sich um die richtig vorhergesagten Klassen durch gegebene Datenpunkte. Datensätze die zu einer Klasse gehören, nennt man klassifizierte Beispiele. Diese Beispiele werden je nach Verwendung für das Trainieren, Validieren oder das Testen der Künstliche Intelligenz genutzt. Während des Trainingsvorganges erkennt ein Modell vorhandene Muster aus den Daten und kann daraus später neue Daten klassifizieren. Der Klassifizierungsvorgang ist in zwei Schritten unterteilt. In dem ersten Schritt findet, wie bereits erwähnt, die Trainingsphase statt. Durch vorhandene Beobachtungen, die bereits einer Klasse zugeordnet sind, lernt der Klassifizierer und erkennt Muster. Damit die Leistung des Trainingsvorganges bewerten werden kann, findet parallel eine Validierung statt. Dafür werden dann die Validierungsdaten eingesetzt. Im zweiten Schritt findet die Testphase statt, in die Beobachtungen einfließen, bei denen es sich um nicht klassifizierte Beispiele handelt. Diesen bisher unklassifizierten Beobachtungen werden in diesem Schritt die Klassen zugeordnet. Hier findet also die eigentliche Klassifizierung statt. Sind nur zwei Klassen für die zuordnung vorhanden, handelt es sich um eine binäre Klassifizierung. Sind mehr als zwei Klassen vorhanden, ist das Klassifizierungsproblem eine Multi-Class Klassifizierung. Im Rahmen dieser Arbeit wird eine Multi-Class Klassifizierung (Mehrklassen Klassifizierung) behandelt \cite{Frochte2021} (S.21) \cite{Asiri2018} \cite{Schoenbrodt2019} (K.2).
	
\section{Überanpassung (Overfitting)}
Im Rahmen des maschinellen Lernens kann es durchaus passieren, dass sich ein Modell während seiner Lern- bzw. Trainingsphase zu sehr an die gegebenen Trainingsdaten orientiert. In diesem Fall spricht man von einer Überanpassung, auch bekannt als Overfitting. Der zweite Fall, der auftreten kann ist, dass ein Modell zu wenig Zusammenhänge erkennt bzw. wiedergibt. Hier spricht man von Underfitting. In dieser Arbeit wird das Problem des Overfittings näher betrachtet, da dies auch im Rahmen der Experimente von Bedeutung sein wird.\\

Bei der Darstellung komplexer Zusammenhänge, kann es von Vorteil sein Neuronale Netze für die Modellierung zu verwenden. Diese haben in der Regel sehr viele freie Parameter, die auch bekannt sind unter dem Namen Gewichte. Der große vorhandene Parameterraum kann aber auch Gefahren mit sich bringen, unter anderem das Problem des Overfittings. Neuronale Netze lernen während der Trainingsphase nicht nur die Trainingsdaten perfekt abzubilden sondern lernen auch Schwankungen in den Daten, Rauschen oder Fehler auswendig. Kommen dann neue Daten ins Spiel, aus denen Prognosen abgeleitet werden sollen, kann es, aufgrund der gespeicherten störenden Einflüsse, zu Verschlechterungen in den Prognosen kommen. Damit findet eine Überanpassung des Modells an die Trainingsdaten statt. Dieses Problem kann auch bei einer polynomialen Regression auftreten. In der nächsten Abbildung sind drei Modellarten in Bezug auf eine Regression zu sehen.\\

\begin{figure}[h!]
	\centering
	\includegraphics[width=15cm,height=5cm]{BeispielÜberanpassungdesModells.png}
	\caption{Darstellung des Overfitting \cite{Vogl2021} (S.341)}
	\label{fig:fig22}
\end{figure}

Die Bilder stammen aus einem linearen Prozess und beinhalten Fehler. Das linke Bild (Overfitting) stellt dar, dass das Modell auch jede Abweichung perfekt erkennt. Das Bild rechts zeigt, dass das Modell die Zusammenhänge zwischen den Inputdaten und Zielvariablen überhaupt nicht erkennt. In dem mittleren Bild ist ein Modell zu sehen, das sich gut auf neue Daten übertragen lässt \cite{Vogl2021} (S.341).\\

Die einfachste Lösung des Problems ist, dass die vorhandenen Daten in drei Datensätze aufgeteilt werden. Somit kann man beobachten, wie sich das Modell auf unbekannte Daten übertragen lässt und konzentriert sich nicht nur auf das Lernverhalten des Modells. Der erste Datensatz wird dann zum Trainieren, der zweite Datensatz für die Validierung und der letzte Datensatz für das Testen verwendet. Diese Aufteilung wurde bereits näher im vorherigen Abschnitt erläutert. Nach der Aufteilung der Daten wird der Fehler auf den Trainingsdaten zusammen mit dem Fehler auf den Validierungsdaten beobachtet. Die Trainingsphase bzw. das Lernen wird gestoppt sobald der Validierungsfehler das Minimum erreicht. Dieser Vorgang wird Early Stopping genannt und wird in der nächsten Abbildung veranschaulicht.\\

\begin{figure}[h!]
	\centering
	\includegraphics[width=10cm,height=6cm]{earlyStopping.png}
	\caption{Early Stopping \cite{Vogl2021} (S.342)}
	\label{fig:fig23}
\end{figure}

Eine weitere Möglichkeit ist die Verwendung eines Dropout-Layers. Diese Schicht veranlasst das Herausfallen von Neuronen in einem neuronalen Netz. Die Auswahl der eliminierten Neuronen passiert zufällig. Dabei werden auch die mit dem Neuron verbundenen eingehende und ausgehende Verbindungen vorübergehend entfernt. Dieser Vorgang ist in nachfolgender Abbildung dargestellt \cite{Srivastava2014}
\newpage
\begin{figure}[h!]
	\centering
	\includegraphics[width=15cm,height=9cm]{
		DropoutNeuronalNetModel.png}
	\caption{Neuronales Netz mit Dropout-Layer \cite{Srivastava2014}}
	\label{fig:fig24}
\end{figure}

Dabei ist auf dem linken Bild ein Neuronales Netz mit zwei Hidden Schichten zu sehen. Rechts ist ein Beispiel abgebildet, wie ein Netz mit eliminierten Neuronen durch die Anwendung des Dropout-Layers aussehen kann. Auch die entfernten Verbindungen werden hier deutlich. Neuronen, die während der Trainingsphase nicht entfernt werden, werden hochskaliert, damit die Summe über alle Eingaben unverändert bleibt. Im Rahmen der Experimente wird, um Overfitting zu vermeiden, ein Dropout-Layer eingesetzt \cite{tensorflow2022}.

\section{Künstliche Neuronale Netze}

Im folgenden Abschnitt werden die Bestandteile von künstlichen Neuronalen Netzen definiert und der Aufbau beschrieben.

\subsection{Neuronales Netz}\label{chapter:NeuronalesNetz}
	
Auf der linken Seite der Abbildung \ref{fig:fig2}, befinden sich die Eingabedaten die als $x_{0}, x_{1}, ..., x_{n} \in{\vec{X}}$  definiert sind, wobei $\vec{X}$ den Vektor $\mathbb{R}^n$ darstellt. Jede einzelnen Eingabe $x_{0}, x_{1},...,x_{n}$ wird mit seinem Gewicht $w_{n,j}$ multipliziert, wobei $j \in{[0,Anzahl Neuronen]}$ gilt. Nachdem multiplizieren mit den Gewichten werden alle berechneten Werte an die Übertragungsfunktion übergeben. Dieser Ablauf ist dabei an eine echte Nervenzelle angelehnt, indem Neuronen aus anderen Nervenzellen, dieses Neuron anregen und auf diese übertragen können. Die Übertragungsfunktion summiert diese Werte zusammen und leitet sie dann an die Aktivierungsfunktion weiter. Die Aktivierungsfunktion beinhaltet genauso ein Schwellenpotenzial mit der wir auch Schwellenwerte prüfen können. Eine einfache Aktivierungsfunktion wäre hierbei das Alles-oder-nichts-Prinzip. Mit diesem Prinzip ist gemeint, dass bei Überschreitungen des Schwellwertes das Neuron aktiviert und unterhalb des Schwellwertes inaktiv gestellt wird \cite{Frochte2021}(S.169).
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=10cm,height=4cm]{Abbildung_NeuronaleNetze_1.png}
	\caption{Modell eines Neurons \cite{Abbildung2}}
	\label{fig:fig2}
\end{figure}
\newpage
	
Zunächst ist wichtig wie die Vernetzungen und Verknüpfungen der Neuronen aussehen und funktionieren. In Abbildung \ref{fig:fig3} wird deutlich, dass ein einfaches Künstliches Neuronales Netz aus drei Schichten besteht. Die erste Schicht ist dabei die Eingabeschicht (engl. Inputlayer), die die Eingabe der Daten verarbeitet und wiederum mit jedem Neuron aus der verborgenen Schicht (engl.= Hiddenlayer) vernetzt ist. Durch die Ausgabeschicht werden Regeln, die aus der verborgenen Schicht extrahiert werden, bereitgestellt. Diese Neuronen werden zur Evaluation des Modells benutzt \cite{Frochte2021}(S.169).
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=8.5cm,height=6cm]{Abbildung_NeuronaleNetze_2.jpg}
	\caption{Schichten der Künstliche Neuronale Netze \cite{Abbildung3}}
	\label{fig:fig3}
\end{figure}
	
\subsection{Feed-Forward Propagierung}

Das neuronale Netz durchläuft bei jedem Dateineintrag einmal alle Schichten. Verwendet wird dafür, dass im Abbild \ref{fig:fig2} vorgestellte Modell.

\subsubsection{Mathematische Beschreibung eines Feed-Forward Netzes}

In den vorherigen Abschnitten wurden die Bestandteile und deren Funktionen näher erklärt. An dieser Stelle wird das einfache neuronale Netz beschrieben. Dafür wird zuerst die Arbeitsweise zwischen den Schichten definiert:

\begin{center}
	$f: \mathbb{R}^{D_{0}} \to \mathbb{R}^{D_{l}}$ , $f(\overrightarrow{X})$ = $(f_{l} \circ f_{l-1} \circ ... \circ f_{1})(u)$,
\end{center}

wobei $f_{l}$ die Schichten sind und für jedes L $\in$ \{ $0, 1, 2, ..., l$ \} die Funktion,\\

\begin{center}
	$f: \mathbb{R}^{D_{L-1}} \to \mathbb{R}^{D_{0}}$ , $f_{l}(\overrightarrow{X}) = \phi (w^{l} * \overrightarrow{X} + b^{l} ) $, beschreibt.
\end{center}

Wobei $\overrightarrow{X}$ der Vektor für die Eingabedaten (engl. Inputdata), $w^{l}$ $\in$ $\mathbb{R}^{(D_{l} \times D_{l-1})}$ die Gewichte, welche die Verbindungen (Abbild \ref{fig:fig3}) von einem Neuron zu anderen Neuronen gewichten und $b^{l}$ der Verzerrungsvektor (engl. Bias) der Schicht $l$ ist. Des weiteren ist $\phi$ die Aktivierungsfunktion der Schicht $l$ \cite{Plaue2021} (S.232 - 234).
	

	
\begin{figure}[h!]
	\centering
	\includegraphics[width=15cm,height=6cm]{FF_Netz.png}
	\caption{Feed-Forward Netz \cite{Halil2022}}
	\label{fig:fig10}
\end{figure}

Die Gewichte werden zunächst zufällig vergeben und mit dem Lernverfahren, das während der Rückpropagierung stattfindet, optimiert. Damit das Neuronale Netz Abweichungen erkennen kann, werden Bias verwendet, die diese Abweichung darstellen. Bevor mit der   Trainingsphase begonnen wird, sollten folgende Elemente festgelegt werden. Zunächst ist die Verlustfunktion zu definieren, welche die Leistung der Trainingsdaten beschreibt. Durch die Verlustfunktion kann das Neuronale Netz die Gewichte optimieren. Als nächstes sollte die Menge an Trainingsdaten und Testdaten festgelegt werden \cite{Chollet2018} (K.2.1 Listing 2.2). An dieser Stelle werden beispielhaft die Schritte der Feed-Forward Propagation in Abbild \ref{fig:fig10} betrachtet. Zunächst wird die Eingabeschicht mit den Eingabedaten gefüttert, wobei diese normalisierte Werte beinhalten sollten. Die zufällig generierten Gewichte stellen die Gewichtungen für die Neuronen der nächsten Schicht dar. Nun wird das, in Abbild \ref{fig:fig10} definierte, Modell für jedes Neuron aus der nächsten Schicht angewendet. Somit hat das erste Neuron aus der Schicht $l=1$  folgende Berechnung. 
	
\begin{center}
	$f_{11} =  \phi [(x_{1}* w_{11}) +( x_{2}* w_{21}) + (x_{3}* w_{31})]  + b^{1}$
\end{center}

Allgemein lässt sich die Feed-Forward Propagierung wie folgt beschreiben:

\begin{center}
	$f = \sum^{n}_{n=0} [ \phi (x_{n} * w_{nj} + b^{j})]$
\end{center}

, wobei $n$ die Anzahl an Neuronen in der vorherigen Schicht sind und $j$ die Anzahl an Neuronen in der aktuellen Schicht. Somit kann das Neuronale Netz mit den bestmöglichen Gewichten Prognosen, anhand der Eingabedaten, liefern. Die Optimierung der Gewichte werden im Abschnitt \ref{chapter:Lernverfahren} Lernverfahren näher beschrieben.\\
	
\subsection{Eingabedaten}
Die Eingabedaten $x_{1}, ..., x_{n}$ stellen die Merkmale (oder Attribute) dar, welche die Eigenschaften beinhalten, aus denen das Neuronale Netz lernen kann. Zu beachten sind dabei die Datentypen der Eingabedaten und die Normierung dieser Daten. Dabei gibt es unterschiedliche Datentypen. Im Rahmen dieser Arbeit ist der Fokus auf Vektor- und Bilddaten gerichtet \cite{Chollet2018} (K.2.2.8). 

\subsubsection{Vektordaten}

Die Vektordaten werden mathematisch als $ \overrightarrow{x} \in \mathbb{R}^{2}$ definiert und beinhalten in der ersten Achse, die Datenwerte, wie zum Beispiel $x_{1}$. Die zweite Achse ist die Merkmalsachse, welche die Merkmale darstellt die zur Verfügung stehen  \cite{Chollet2018} (K.2.2.9).

\subsubsection{Bilddaten}

Bei den Bilddaten handelt es sich generell um drei dimensionale Matrizen, jedoch unterscheiden wir die Graustufenbilder, für die zwei dimensionale Matrizen ausreichen. Hier bekommt jeweils eine Achse die Höhe, die zweite Achse die Breite und die letzte Achse die Farbtiefe des Bildes. Da die Graustufenbilder nur einen Farbkanal beinhalten, ist die zwei dimensionale Matrix ausreichend \cite{Chollet2018} (K.2.2.11).

\subsection{Lernverfahren}\label{chapter:Lernverfahren}
Bisher wurde der Durchlauf eines Neuronalen Netzes definiert, jedoch nicht wie es aus den Daten lernen kann. Damit das Neuronale Netz lernen kann, muss er auch Fehler erkennen können. Je nach Größe oder Art der Ziel-Klassen wird eine Aktivierungsfunktion ausgewählt. Ein Beispiel dazu ist die Mehrklassen Klassifizierung, bei der die Aktivierungsfunktion Softmax ausgewählt wird. Die Softmax-Funktion, die auch als Softmax-Regression bekannt ist, stellt anhand der Eingabewerte eine Wahrscheinlichkeitsverteilung zur Verfügung, deren Summe 1 ergibt. Somit werden den Ziel-Klassen Werte vergeben die zwischen 0 und 1 liegen \cite{Mahmood2018}. Durch die Vereinheitlichung der Neuronen mit der Aktivierungsfunktion, können Fehlerwerte kalkuliert werden. Dies geschieht durch die Annahme, dass die Ausgabeschicht den Wert $x_{0} = 0.75$ beinhaltet, wobei der echte erwartete Wert $y = 1$ ist. Durch die Anwendung  eines der Verlustfunktionen, stellt das Neuronale Netz fest, wie groß die Abweichung des Ergebnisses von dem tatsächlichen Ergebnis ist. Hierzu werden unterschiedliche Verfahren genutzt  \cite{Matzka2021}(S.124-126). Eines dieser Verfahren ist die mittlere quadratische Abweichung (engl. mean squared error, MSE).

\begin{center}
	\centering
	$MSE = \frac{1}{n} \sum\limits_{i=1}^{n}(Y_{i} - \hat{Y_{i}})^{2}$
\end{center}

, wobei $n$ Anzahl der Datenpunkte, $Y_{n}$ das erwartete Ergebnis und $\hat{Y_{i}}$ die prognostizierten Werte sind.\\

Mit den vorher angenommenen Werten wird der Fehler wie folgt berechnet.

\begin{center}
	$MSE = \frac{1}{1} \sum\limits_{i=1}^{1}(Y_{i} - \hat{Y_{i}})^{2}$\\

	$MSE = 1 * (1 - 0.75)^{2} = 0.0625$\\
\end{center}

Somit kennt das Neuronale Netz die Abweichung der Prognose, womit es den Lernprozess starten kann. Es stellt sich die Frage wie das Neuronale Netz sich optimieren bzw. verbessern lässt. \cite{Plaue2021} (S.194).  Es ist bekannt das ein Neuronales Netz mehrere Ausgaben liefern kann und für jeder dieser Ausgaben ist es möglich eine Verlustfunktion zuzuweisen. \cite{Chollet2018}.

\subsubsection{Verlustfunktion}

Die Verlustfunktion (engl. loss-, costfunktion) wird für die Optimierung während der Trainingsphase genutzt. Hierzu gibt es verschiedentliche Funktionen wie zum Beispiel die oben genannte mittlere quadratische Abweichung. Ein anderes Beispiel ist die Cross-Entropy-Loss Funktion, welche für die Optimierung von Klassifizierungs-Modellen geeignet ist. Die Cross-Entropy-Loss Funktion ist ähnlich wie die Softmax-Funktion aufgebaut. Sie misst den Abstand zwischen dem prognostizierten Wert und dem Wahrheitswert, um den Fehler zu erkennen und die Gewichte so anzupassen, dass das Modell bessere Ergebnisse erzielt. Während der Trainingsphase werden die Gewichte iterativ und entsprechend mit dem Ziel, den Cross-Entropy-Loss zu minimieren, angepasst \cite{Mahmood2018}. Im Rahmen dieser Arbeit wird die Cross-Entropy-Loss Funktion angewendet, da es sich um eine Mehrklassen Klassifizierung handelt.

\subsubsection{Rückpropagierung}

Die Anpassung der entsprechenden Gewichte wird durch die Rückpropagierung er-möglicht. Damit die Gewichte angepasst werden können, ist es notwendig, dass die Verlustfunktion des Modells ein Minimum annimmt. Es ist bekannt, dass mit dem Gradienten der Funktion das Minimum erreichbar ist, welches die partielle Ableitung aller Vektoren darstellt. Dieser Vektor wird auch $\delta(f)$ genannt. Er zeigt an jedem Punkt der Funktion, die Richtung des steilsten Anstiegs  (bzw. Maximums). $-\delta(f)$ zeigt die Richtung des steilsten Abstiegs (bzw. Minimums) der Funktion \cite{Vogl2021} (S.337) an. Allgemein wird das Gradientenverfahren folgendermaßen dargestellt:\\

\begin{center}
	$x^{i+1} = x^{i} - \eta * \delta(f(x^{i}))$
\end{center}

, wobei $x^{0}$ der Startpunkt ist und $\eta$ die Schrittweite, welche auch als die Lernrate beschrieben wird. Dieses Verfahren lässt sich wie folgt bei den Gewichten integrieren.

\begin{center}
	$w_{neu} = w_{alt} - \eta * \delta (E(W_{alt}))$
\end{center}

, wobei $w$ das Gewicht darstellt und $\eta$ die Schrittweite.\\
\\
Somit kann das Neuronale Netz seine Gewichte anpassen und eine Optimierung ermöglichen. Die partielle Ableitung der Fehlerfunktion $E$, wird durch die Verwendung der Kettenregel bestimmt.

\begin{center}
	$\frac{\delta E(W)}{\delta w_{ij}} =\sum_{k=1}^{n}[\frac{\delta}{\delta w_{ij}}(\frac{1}{2}(Y_{i} - \hat{Y_{i}})^{2})]$
\end{center}

, wobei $Y_{i}$ der prognostizierter Wert ist und $\hat{Y_{i}}$ der erwartete Zielwert. Dabei muss beachtet werden, dass die $Y_{i}$ Werte von Anfang an bekannt sind. Somit berechnet das Modell den Fehler mit der Fehlerfunktion und wendet die partielle Ableitung auf diese an. Dadurch werden die Gewichte mit der oben genannten Formel angepasst. \cite{Vogl2021} (S.337-338). 

\subsubsection{Ablauf der Fehlerrückführung}

Damit dieser Ablauf genauer beschrieben wird, müssen die Schritte zur Optimierung des Modells definiert werden. Zunächst muss die Feed-Forward Propagierung stattfinden, damit die Gewichte $W^{l}$ und Bias $b^{l_{j}}$ (siehe Abbild \ref{fig:fig10}), wobei $l$ den Index von der Schicht darstellt, initialisiert werden. Als nächstes wird der Ausgabefehler berechnet, welches die Verlustfunktion darstellt. Durch diese Funktion wird die Größe des Fehlers berechnet. Im darauffolgendem Schritt, findet die Fehlerrückführung statt, welche durch die Rückpropagierung ermöglicht wird. Bei der Fehlerrückführung wird für jede Schicht $l$ $\in{L-1, L-2, ..., 1}$ folgende Berechnung durchgeführt.

\begin{center}
	$\delta^{l} = (D\phi_{l}(x^{l}))^{T} * (w^{l+1})^{T} * \phi_{l+1}$
\end{center}


Nachdem diese Schritte vollständig bearbeitet wurden, werden die Gewichte angepasst, wodurch das Modell optimiert wird \cite{Plaue2021} (S.243).

\section{Deep Learning}

Bei Deep Learning handelt es sich um eine Teilmenge der Maschinellen Lernalgorithmen, mit der komplexere Aufgaben gelöst und automatisiert werden können. Der Unterschied zu einem Künstlichen Neuronalen Netz ist, dass Deep Learning mehrere verborgene Schichten beinhaltet (siehe Abbildung \ref{fig:fig4}). Hierzu ist die Aktivierungsfunktion als die Sigmoid-Funktion vorgesehen, die wie folgt definiert ist:

\begin{center}
	$sig(t) = \frac{1}{(1 + e^-t)}$\\
\end{center}

,wobei $sig(t) \in [0,1]$ und $ t \in \mathbb{R}$ gilt. 
\\

Dies bedeutet, dass die Neuronen immer eine Zahl übertragen bekommen, die zwischen 0 und 1 liegt. Somit können durch Implementierungen Schwellenwerte definiert und dementsprechend Neuronen aktiviert oder deaktiviert werden \cite{Frochte2021}(S.178). \\

\begin{figure}[h!]
	\centering
	\includegraphics[width=13cm,height=7cm]		{Abbildung_DeepLearning_1.jpg}
	\caption{Künstliches Neuronales Netz vs. Deep Learning \cite{Abbildung4}}
	\label{fig:fig4}
\end{figure}

\subsection{Convolutional Neural Network}

Bei einem CNN, im Deutschen "gefaltetes Neuronales Netzwerk", handelt es sich von einer Sonderform des künstlichen neuronalen Netzes, das speziell für Bild- oder Audiobearbeitung entwickelt wurde. Diese Form ist teils an den biologischen Ablauf angelehnt.\cite{Luber2019} Der Aufbau eines CNNs ist in Abbildung \ref{fig:fig5} dargestellt.

\begin{figure}[h!]
	\centering
	\includegraphics[width=13cm,height=6cm]		{Abbildung_CNN_1.png}
	\caption{Aufbau eines CNNs \cite{Abbildung5}}
	\label{fig:fig5}
\end{figure}

In Abbildung \ref{fig:fig5} sind mehrere Schichten (Layer) zu sehen. Dabei ist die Eingabeschicht (Inputlayer) und die Ausgabeschicht (Outputlayer) bekannt. Wie im vorherigen Abschnitt auch definiert, hat ein CNN mehrere verborgene Schichten, darunter den \textbf{Convolutional Layer}, der einzelne Merkmale aus den Eingabedaten ortsunabhängig erkennt und daraufhin diese extrahiert. Diese Merkmale könnten bei einer Bildverarbeitung den Kanten, Linienformen, Farbtupfer und Faltung entsprechen, die eine Struktur darstellen. Ein Beispiel dazu wird im folgenden Abbild dargestellt.

Diese Merkmale werden in der \textbf{Pooling-Schicht}, auch als Subsampling bekannt, bearbeitet, indem die Auflösung der Merkmale reduziert und verdichtet wird. Die Pooling-Schicht enthält keine Modellparameter, weshalb das Modell durch diese Schicht nicht wirklich lernt. Somit werden überflüssige Informationen verworfen, wodurch die Datenmenge reduziert wird. Dadurch wird die Berechnungsgeschwindigkeit erhöht. Diese zwei Schichten können so oft wie möglich verwendet werden, da sie nur Merkmale aus den Bilder extrahieren und optimierend zu Verfügung stehen. Die eigentliche Klassifikation entsteht durch den \textbf{Fully-Connected Layer}, im Deutschen "vollständig verknüpfte Schicht", der sich der wiederholten Abfolge der Convolutional- und Pooling-Schichten anschließt, indem alle Merkmale der vorgelagerten Schichten mit jedem Ausgabemerkmal verknüpft sind. Somit werden mögliche Kombinationen aus den Strukturen entworfen, die komplexere Strukturen identifizieren lassen. Wichtig ist hierbei, dass die Anzahl an Neuronen in der vollständig vernetzten Schicht abhängig von den Klassen oder Objekten sind \cite{Luber2019}. 
	
\section{Evalutionsmetriken}
	
Für die Bewertung eines Klassifizierungsvorgangs werden Performance-Metriken be-nötigt. Diese Metriken lassen sich aus den relevanten Häufigkeiten der Fehler des Klassifikators welcher er während der Zuordnung der Objekte macht, herleiten. Metriken, die für bei einer Mehrklassen-Klassifizierung verwendet werden können, sind die gleichen Metriken wie für Binäre-Klassifikationsprobleme. Die Metriken werden dabei für jede einzelne Klasse berechnet. Ein beliebtes Verfahren für die Bewertung ist dabei die Wahrheitsmatrix (Konfusionsmatrix). Hier werden die relevanten Häufigkeiten in einer Tabelle dargestellt. Aus dieser Tabelle können dann die Performance-Metriken abgeleitet bzw. berechnet werden. In der nächsten Abbildung ist eine Konfusionsmatrix zu sehen, die ein Beispiel zur Spam-Erkennung beinhaltet \cite{Burkov2019} (K.5.6.1).

\begin{figure}[h!]
	\centering
	\includegraphics[width=12cm,height=5cm]		{Wahrheitsmatrix.png}
	\caption{Konfusionsmatrix  \cite{Burkov2019}(K.5.6.1)}
	\label{fig:fig21}
\end{figure}

Die Achsen der Matrix geben die tatsächlichen und vorhergesagten Kennzeichnungen an. Bei einem binären Klassifikationsproblem gibt es zwei Klassen. In diesem Beispiel sind das „Spam“ und „Kein$\_$Spam“.  Aus der Matrix kann in diesem Fall abgelesen werden, dass von 24 Beispielen, die tatsächlich Spam waren, 23 vom Modell auch richtig als Spam klassifiziert wurden. Es wurden also 23 richtig positiv (RP) klassifiziert. Ein Beispiel wurde fälschlicherweise als „Kein$\_$Spam“ klassifiziert, obwohl es sich dabei um Spam handelte. Dieses Beispiel wurde also falsch negativ (FN) klassifiziert. Außerdem wurden von 568 Beispiel, die eigentlich Spam waren, 556 richtig und 12 wurden falsch klassifiziert. Dies bedeutet, es sind 556 richtig negative (RN) und 12 falsch positive (FP) Klassifizierungen vorhanden. Die positive Klasse ist dabei „Spam“ und die negative Klasse „Kein$\_$Spam“ \cite{Burkov2019} (K.5.6.1). \\

Möchte man diese Art von Bewertung für ein Mehrklassen-Klassifikationsproblem (Multi-Class-Klassifikationsproblem) anwenden, muss die Anzahl der Zeilen und Spalten der Matrix, der Anzahl der verschiedenen vorhandenen Klassen entsprechen. Die Wahrheitsmatrix wird zum Beispiel für die Berechnung von Präzision (Precision), Trefferquote (Recall) oder Korrektklassifikationsrate (Accuracy) verwendet. Es gibt noch weitere Metriken, die aus der Matrix abgelesen werden können. Jedoch werden nur die drei genannten Metriken im Rahmen dieser Arbeit und damit für die Bewertung der Experimente verwendet \cite{Burkov2019} (K.5.6.1).  

\subsection{Präzision (Precision) und Trefferquote (Recall)} 

Die am häufigsten verwendeten Metriken sind Precision und Recall. Diese Größen werden auch für die Evaluierung der Modelle verwendet. Mit diesen Metriken kann eine Leistungsbeurteilung eines Modells erfolgen.  \\

Die Präzision eines Modells gibt das Verhältnis der richtigen positiven Vorhersagen zu den positiven Vorhersagen insgesamt an: 

\begin{center}
	Präzision = $\frac{RP}{RP + FP}$
\end{center}
 
Die Trefferquote eines Modells gibt das Verhältnis der richtigen positiven Vorhersagen zu der Gesamtheit der tatsächlich positiven Beobachtungen an.  

\begin{center}
	Trefferquote = $\frac{RP}{RP + FN}$
\end{center}

Diese Metriken finden vor allem bei binären Klassifikationsproblemen Anwendung, können jedoch auch zur Bewertung von Multi-Class Klassifikationsproblemen verwendet werden. Man wählt dafür zunächst eine Klasse aus, für die man diese Metriken ermitteln möchte und ordnet alle zu dieser Klasse gehörenden Beobachtungen den Positiven zu. Alle anderen Beispiele der restlichen Klassen werden dann den Negativen zugeordnet. Somit kann diese Metrik für jede Klasse einzeln berechnet werden und am Ende zum Beispiel durch die Betrachtung des Mittelwerts auch im Gesamten bewertet werden \cite{Burkov2019} (K.5.6.2).
	
\subsection{Korrektklassifizierungsrate (Accuracy) }
	
	Eine weitere Metrik, die aus der Wahrheitsmatrix berechnet werden kann, ist die Korrektklassifizierungsrate, auch bekannt als Accuracy. Diese Metrik gibt die Anzahl der richtig klassifizieren Beispiele im Verhältnis zur Gesamtzahl aller klassifizierten Beispiele bzw. vorhandener Daten an. Die Metrik ist gegeben durch:
	
\begin{center}
		Korrektklassifikationsrate  =$\frac{RP + RN}{RP + RN + FP + FN}$
\end{center}
	
Diese Metrik ist vor allem dann eine sinnvolle Größe, wenn die vorhandenen Klassen im Datensatz gleich wichtig sind. Bei der Auswahl von Metriken für einen Klassifikationsvorgang ist vor allem das Ziel bzw. die Wichtigkeit der einzelnen Metriken zu beachten. In dem Beispiel der Spam Erkennung wird man falsch negative Klassifizierungen eher in Kauf nehmen als falsch positive. Den eine falsch positive Erkennung von Spam-Mails würde bedeuten, dass das Modell die Mail fälschlicherweise als Spam klassifiziert und die E-Mail dadurch im Posteingang nicht erscheint und untergeht. Bei einer falsch negativen Klassifizierung würde die E-Mail fälschlicherweise als kein Spam klassifiziert werden und sie wäre im Posteingang sichtbar \cite{Burkov2019} (K.5.6.3).  
	
\newpage
\chapter{CRISP-DM Modell}
	
Das CRISP-DM Modell "Cross-Industry Standard Process for Data Mining" beschreibt den Standard für die Strukturierung der Maschinellen Lernalgorithmen. Das Ziel ist es, einen einheitlichen Prozess für Data Mining Projekte zu schaffen und ist eine Anleitung für Data Mining, die in 6 Schritten aufgeteilt ist \cite{Wuttke}. Der Ablauf des Modells ist in Abbildung \ref{fig:fig6} dargestellt.
	
	\begin{figure}[h!]
		\centering
		\includegraphics[width=9cm,height=8cm]		{Abbildung_CRISP_DM_1.png}
		\caption{Ablauf CRIPS-DM Modell \cite{Abbildung6}}
		\label{fig:fig6}
	\end{figure}
	
	\subsubsection{Business Understanding}
	
	Der erste Schritt der 6 Schritte des CRISP-DM Modells, ist das Business Understanding, welches sich mit den betriebswirtschaftlichen Problemen befasst. Zunächst werden betriebswirtschaftliche Anforderungen extrahiert und analysiert, wodurch die Grundlagen für weitere Schritte und Entscheidungen gebildet werden. Damit ein Verständnis über die betriebswirtschaftlichen Fragestellungen übermittelt wird, ist es wichtig die Anwender in die Data Mining Prozesse mit einzubeziehen.\\
\\
Das Business Understanding beinhaltet 4 Aspekte, die in Betracht gezogen werden sollen. Hierzu gehört wie zuvor auch erwähnt, die Bestimmung der betriebswirtschaftlichen Problemstellungen und dessen Zielkriterien. Ein weiterer Aspekt, ist die Situationsbewertung, welches die zur Verfügung gestellten Ressourcen für das Data Mining Projekt beschreibt. Dies bedeutet zum Beispiel die Software- und Personalressourcen. Zusätzlich werden Risiken, die, während dem Data Mining Projekt entstehen können, identifiziert. Auch die Bestimmung analytischer Ziele ist ein Aspekt des Business Understanding, indem eine Analyse der zuvor bestimmten betriebswirtschaftlichen Probleme durchgeführt wird. Auch Erfolgskriterien für das Data Mining Projekt werden bestimmt, wie zum Beispiel eine Optimierung des Geschäftsprozesses um 5\% mit weniger Bedarf an Ressourcen. Der letzte Aspekt beinhaltet die Erstellung des Projektplans, welches die beabsichtigten Ziele des Projektes beschreibt, indem die Auflistung der einzelnen Schritte mit jeweiliger Zeitspanne definiert werden. Hinzu kommen die möglichen Risken oder Ursachen für das Scheitern des Projektes, die aufgefasst werden \cite{Burkov2019} (K.5.6.3).
	
\subsubsection{Data Understanding}
	
In diesem Schritt werden relevante Datenbestände, die zu einer Hypothese führen können, aufgestellt. Zum Beispiel werden bei einer Wettervorhersage die aktuellen Zustände der Atmosphäre betrachtet. In diesem Fall ist der Datenbestand die Zustände der Atmosphäre. Zunächst werden Daten gesammelt, die benötigt werden und zu einer bereits bestehenden Datenmenge integriert. Als nächstes werden diese Datenbestände beschrieben. Hierzu werden Eigenschaften wie Quantität, Formateigenschaften, Anzahl der Einträge und Felder der Daten erfasst. Der letzte Schritt des Data Understanding ist die Untersuchung und die Bewertung der Daten, in dem eine Analyse mit den Daten betrieben wird, um erste Hypothesen und Erkenntnisse zu treffen und diese dann zu dokumentieren. Bei der Bewertung der Daten wird sichergestellt, dass die Daten verwendbar sind und sie keine fehlende Attributwerte enthalten \cite{Wuttke}.
	
\subsubsection{Data Preparation}
	
Um die finale Menge der Datenauswahl zu erstellen, wird der Schritt Data Preparation durchgeführt. An erster Stelle werden Daten ausgewählt, die für das Ziel des Projektes relevante Informationen hergeben. Wichtig hierbei ist zu betrachten, dass die Daten in dem richtigen Datenformat gespeichert werden \cite{Wuttke}.
	
\subsubsection{Modeling}
	
Um eine vorliegende Problemstellung aus dem Bereich Maschinelles Lernen lösen zu können, stehen verschiedene Modelle beziehungsweise Algorithmen zur Verfügung. Aus diesen Modellen wird dann das Modell ausgesucht, welches im Bezug zum definierten Ziel das optimale Ergebnis liefert. Manche Modelle benötigen hierzu vorbestimmte Datenstrukturen, die dazu führen können, einen Schritt zurück zu gehen und sich noch einmal mit der Datenvorbereitung zu befassen. Anschließend wird das Modell trainiert und getestet um die Qualität und Genauigkeit des Modells zu überprüfen \cite{Wuttke}.
	
\subsubsection{Evaluation}
	
Vor der Finalisierung des Data Mining Projektes, ist es noch notwendig zu prüfen, ob die Qualität des Modelles für das Ziel des Projektes ausreicht. Ist das Ergebnis noch nicht gut genug oder werden vorher definierte Ziele nicht erreicht, müssen die Gründe für das Scheitern analysiert und entsprechende Änderungen im Modell vorgenommen werden. Dies hat zufolge, dass die vorherigen Schritte nochmals durchlaufen werden müssen \cite{Wuttke}.
	
\subsubsection{Deployment}
	
Als letztes werden die aus dem erstellten Modell gewonnen Erkenntnisse für die Nutzer vorbereitet und ihm als Anwendung zur Verfügung gestellt. Damit kann ein Anwender zum Beispiel eigene Daten in das Modell hochladen und erhält, je nach der vorliegenden Problematik, ein Ergebnis für seine verwendeten Daten \cite{Wuttke}.
	
\newpage
\chapter{Experimente}
	
\section{Business Understanding}
	
Online-Versandhändler haben oft eine hohe Rückläuferquote. Diese Rückläuferquote kommt zum Beispiel durch den Kauf von Artikeln in verschiedenen Größen zustande. Die nicht passenden Größen werden dann vom Käufer wieder zurückgesendet. Unter diese Versandhändler fällt, mit einer Rückläuferquote von bis zu 50\%, auch das Unternehmen Zalando. Dabei müssen 97\% der zurückgesendeten Produkte wieder eingelagert und verkauft werden \cite{Hoefer2018}. Für den erneuten Verkauf werden die Produkte, in diesem Betrachtungsfall Klamotten, identifiziert, gelabelt und bei Bedarf wieder eingelagert. Das Unternehmen Zalando verschickte im Jahr 2019 rund 186 Millionen Bestellungen \cite{Rabe2021}. Wenn man davon ausgeht, dass eine Bestellung 4 Artikel beinhaltet und 50\% der Bestellungen wieder zurückgesendet werden, ergibt das 372 Millionen Artikel, die wieder neu gelabelt und eingelagert werden müssen.\\
	
Die Unterstützung und Optimierung der Rückläuferbearbeitung, kann zum Beispiel durch eine AI gestützte Klassifikation gewährleistet werden. Mit diesem Ansatz kann dann die zu einem Artikel zugehörige Kategorie, auf Basis von Bildern, bestimmt werden. Damit ergibt sich die Frage- bzw. Problemstellung, inwiefern können Machine Learning Algorithmen bei der Klassifizierung von Bildern einzelner Kleidungsstücke unterstützen?
	
\section{Data Understanding}
	
Der für diese Arbeit gewählte Datensatz heißt Fashion MNIST und wurde im Jahr 2017 von dem Unternehmen Zalando veröffentlicht. Der Datensatz steht in einer GitHub Repository zur Verfügung und ist frei zugänglich \cite{Zalando2017}. Er beinhaltet Zalando-Artikelbilder, die in zwei Datensätze aufgeteilt sind. Der erste Satz enthält 60.000 Beispiele, die für das Training verwendet werden und der zweite Satz 10.000 Beispiele, die für das Testen verwendet werden. Jedes Beispiel, welches jeweils ein Bild darstellt, ist ein 28x28 Graustufenbild. Jedem Bild wird dabei noch ein Label zugeordnet. Ein Label repräsentiert eins der 10 Klassen, wobei jede Klasse eine Artikelkategorie darstellt. In der folgenden Abbildung \ref{fig:fig7} ist eine Übersicht des Datensatzes bzw. der Bilder zu sehen. Dabei werden pro Klasse drei Zeilen beansprucht.\\
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=15cm,height=15cm]		{Abbildung_DatensatzAlsBild.jpg}
	\caption{Der gesamte Datensatz: FASHION-MNIST \cite{Abbildung7}}
	\label{fig:fig7}
\end{figure}
	
Der ursprüngliche MNIST Datensatz, der durch Fashion-MNIST ersetzt wurde, ist sehr beliebt und wird oft verwendet, um Algorithmen zu validieren. Es heißt auch „If it doesn't work on MNIST, it won't work at all". Jedoch wurde der MNIST Datensatz aufgrund seiner Einfachheit ausgetauscht \cite{Zalando2017}.\\
	
Auch die Labels bestehen aus 28x28 Pixeln, wobei jeder einzelne Pixel einen Wert zwischen 0 und 255 annehmen kann. Der aktuelle Datensatz Fashion-MNIST enthält folgende 10 Klassen bzw. Labels:

\begin{table}[h!]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Label & Artikel \\
			\hline
			0 & T-shirt/top \\
			\hline
			1 & Trouser \\
			\hline
			2 & Pullover \\
			\hline
			3 & Dress \\
			\hline
			4 & Coat \\
			\hline
			5 & Sandal \\
			\hline
			6 & Shirt \\
			\hline
			7 & Sneaker \\
			\hline
			8 & Bag \\
			\hline
			9 & Ankle boot \\
			\hline
		\end{tabular}
		\caption{Labels des Datensatzes}
		\label{tab:labels}
	\end{center}
\end{table}
	
\newpage 
	
Der Trainings- als auch der Testdatensatz ist ziemlich ausgeglichen. In jedem Satz ist jede Kategorie mit ca. 10\% vertreten, was in den nächsten Abbildungen zu sehen ist.
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=9cm,height=8cm]		{Abbildung_StatistikVerteilungTrainDatensatz.jpg}
	\caption{Verteilung Trainingsdatensatz \cite{Abbildung8}}
	\label{fig:fig8}
\end{figure}
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=9cm,height=8cm]		{Abbildung_StatistikVerteilungTestDatensatz.jpg}
	\caption{Verteilung Testdatensatz \cite{Abbildung9}}
	\label{fig:fig9}
\end{figure}
\newpage
	
Aufgrund der Ausgeglichenheit der Daten müssen im Rahmen der Data Preparation keine großen Änderungen oder Vorbereitungen vorgenommen werden.
	
\section{Data Preparation}
	
Um die vorliegenden Daten für die modellierten ML-Verfahren verwenden zu können, müssen diese entsprechend vorbereitet werden. 
	
\subsection{Test- und Trainingsdaten}
Für die Vorbereitung werden die Trainingsdaten nochmal aufgeteilt. Dabei werden aus den vorhandenen 60000 Trainingssätzen, 6000 für die Validierung extrahiert. Dadurch bleiben für die Trainingsphase 54000 Datensätze übrig. Die Testdatensätze bleiben mit der ursprünglichen Anzahl von 10000 gleich.
	
\subsection{Skalierung der Merkmale}
	
Die Skalierung von Merkmalen dient zur Normalisierung des Bereichs der erklärenden bzw. unabhängigen Variablen. Das Verfahren ist auch als Datennormalisierung bekannt und wurde im Rahmen der Datenvorbereitung auf den Daten angewendet. Die Eingabedaten liegen als Graustufenbilder vor und besitzen Werte zwischen 0 und 255. Um die Normalisierung dieser Daten vorzunehmen, werden die Werte durch 255 geteilt um somit Ausprägungen zwischen 0 und 1 zu erreichen. 
	
\subsection{Datentransformation}
	
In dem Ausgangsdatensatz stellt jede Zeile mit seinen 784 Spalten, die wiederum als 28x28 Pixel zu verstehen sind, jeweils ein Bild dar. Für die spätere Verwendung der Daten, müssen diese aber umgeformt werden. Die Umformung der Graustufenbilder muss so erfolgen, dass ein Bild durch 28 Zeilen und 28 Spalten dargestellt wird und so die Pixel wiedergibt. Dadurch kann das Neuronale Netz eine genaue Position der Pixel identifizieren. Die dafür verwendete Methode kann dem beigefügten Notebook entnommen werden. Im Rahmen der Datentransformation werden außerdem die Zielvariablen in die vorhandenen 10 Kategorien unterteilt.
	
\section{Modellierung}\label{model:model}
	
In diesem Schritt wird ein Maschinelles Lernalgorithmus erstellt und trainiert. Die Optimierung dieses Modells findet in einer bestimmte Reihenfolge statt. Zunächst wird ein Modell erstellt, welches trainiert und mit den Validierungsdaten bewertet wird. Als nächstes wird das Modell in Abschnitt \ref{eval:eval} evaluiert. Durch das Testen ist es möglich das neu implementierte Modell mit dem alten Modell zu vergleichen. Ist man mit den Ergebnissen nicht zufrieden oder das Zielergebnis wurde nicht erreicht, so springt man zur Phase \ref{model:model} Modelliereung zurück und versucht das Modell zu optimieren. Sollten die Zielergebnisse erreicht werden, so geht es mit dem Schritt \ref{dp:dp} Deployment weiter.\\
\\
Insgesamt werden drei verschiedene implementierte Modelle vorgestellt und im nächsten Abschnitt evaluiert. Jedes Modell bzw. Experiment beinhaltet dabei ein Convolutional Neuronal Network. Die Unterschiede der drei Modelle liegen dabei in den verwendeten Schichten und deren Zusammenspiel. 
	
\subsection{Experiment 1}\label{model:ep1}
	
Das erste implementierte CNN-Modell beinhaltet folgende drei Layer, die in vorherigen Abschnitten bereits erläutert wurden:
	
\begin{itemize}
	\item Convolutional Layer (Conv2D)
	\item Pooling Layer (MaxPooling2D)
	\item Flatten Layer (Flatten)
	\item Fully-Connected Layer (Dense)
	\label{tab:model1}
\end{itemize}
	
Der Conv2D und MaxPooling2D Layer gehören, wie in Kapitel 2 beschrieben, zu dem Feature-Extraktor. Die beiden Schichten werden zwei mal nacheinander in das Modell integriert. Im Anschluss werden dem Modell zwei Dense Layer hinzugefügt. Der erste Conv2D Layer bekommt die Eingabedaten im 28x28 Pixel Format, daher erhält diese Schicht einen Input-Parameter, der die Dimension der Eingabedaten beschreibt. Im MaxPooling2D werden die aus den Conv2D extrahierten Merkmale in eine 14x14 dimensionale Matrix zusammengefasst. Der zweite Conv2D Layer erhält nach dem MaxPooling2D Layer Daten in der Form 14x14 Pixeln, aus dem der Layer dann wiederum Merkmale extrahiert. Der anschließende MaxPooling2D Schicht fasst diese Merkmale dann nochmals zusammen. Als nächstes formt der Flatten Layer die Merkmale in eine eindimensionale Matrix um. Zuletzt folgen dann die beiden Dense Layer. Die erste Dense Schicht ist der Fully-Connected Layer und die zweite eingesetzte Dense Schicht der Output Layer (Ausgabeschicht). Der ersten Dense Schicht wird dabei die Aktivierungsfunktion Recitifier übergeben. Die Recitifer (relu) wird wie folgt definiert.
	
\begin{center}
	$f(x) = max(0,x)$, wobei $x$ der Eingangswert ist.
\end{center}

Die Funktion gibt den maximalen Wert zurück, der entweder $x$ oder Null ist. Für die Ausgabeschicht wird die Aktivierungsfunktion Softmax eingestellt. Damit wird das erste Modell finalisiert und kann trainiert werden.
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=10.5cm, height=9.5cm]		{ExperimentModelAufbau_1.png}
	\caption{  Modellaufbau \cite{HK22} (Experiment 1)}
	\label{fig:fig13}
\end{figure}
	
Insgesamt kann das Modell 53,790 Parameter trainieren. Bevor das Training gestartet werden kann, müssen noch einige Variablen definiert werden. Zunächst braucht das Modell ein optimizer der ein tensorflow Objekt darstellt. Dieses Objekt beschreibt den Optimierungsvorgang für das Modell. In diesem Fall wird der optimizer als "tf.keras.optimizers.Adam()" definiert, der das stochastische Gradientenabstiegsverfahren beschreibt. Der nächste Parameter definiert die Verlustfunktion des Modells, welche wir als Cross-Entropy-Loss Funktion angeben. Als Bewertungsmetrik für das Modell, wird die Genauigkeit (engl. accuracy),die Präzision (engl. precision) und die Trefferquote (engl. recall) ausgewählt. Diese Metriken geben prozentual an, wie gut ein Modell prognostiziert. Zuletzt werden Epochen-Anzahl und Batch-Größen angegeben. 
	
\subsubsection{Trainingsphase}
	
Mit der Übergabe der Trainings- und Validierungsdaten wird die Trainingsphase gestartet. Nachdem die Trainingsphase beendet ist werden die Bewertungsmetriken genutzt, um eine Darstellung der Leistung des Modells zu erhalten.
	
\begin{figure}[h!]
	\centering
	\includegraphics[width=14cm, height=10cm]		{ExperimentModelTrainingsphase_1.png}
	\caption{ Bewertung Trainingsphase \cite{HK22}(Experiment 1)}
	\label{fig:fig14}
\end{figure}
	
Die Ergebnisse zeigen, dass die erste Epoche eine Genauigkeit von $86,56\%$ erreicht und diese sich bei den nächsten Epochen erhöht. Damit hat das Modell am Ende der Trainingsphase eine Genauigkeit von $91\%$. Sichtbar ist die Differenz zwischen $accuracy$ ($93,34\%$) und $val\_accuracy$ ($91,14\%$). Die accuracy (auch Genauigkeit genannt) beschreibt in diesem Fall, die Genauigkeit der Trainingsdaten, diese wird jedoch nicht für die Bewertung genutzt. Die $val\_accuracy$, welche die Genauigkeit der Validierungsdaten anzeigt, wird hier stattdessen in Betracht gezogen. Die Daten, die für die Validierung ausgewählt wurden, werden komplett abgekapselt von den Trainingsdaten übergeben. Der nächste Schritt für die Optimierung des Modells, sollte die Anpassung sein, wodurch der Abstand der Genauigkeiten verringert wird. Es ist auch ersichtlich, dass die loss-Werte sich gegen null nähern. Dies zeigt, dass das Modell sich verbessert bzw. optimiert. Die Leistung kann auch anhand eines Graphen dargestellt werden, wobei die Ergebnisse in Epochen aufgeteilt und geplottet werden. Dieser Graph ist in der nächsten Abbildung zu sehen.\\
\begin{figure}[h!]
	\centering
	\includegraphics[width=10cm,height=8cm]		{ExperimentModelBewertungsgraf_1.png}
	\caption{ Bewertung der Trainingsphase anhand eines Graphen \cite{HK22}(Experiment 1)}
	\label{fig:fig15}
\end{figure}
	
In diesem Abbild wird die Verbesserung des Modells durchaus ersichtlicher. Es ist deutlich, dass sich die loss-Werte gegen null nähern, währenddessen die Genauigkeit sich erhöht. Somit wird das Modell immer weiter optimiert bis zur letzten Epoche. Deutlich zu sehen sind die Sprünge der Linien bei den Validierungsmetriken. Eine Erklärung dafür ist die Überanpassung an die Trainingsdaten des Modells, was im nächsten Modellierungsschritt behandelt werden muss. Zunächst wird das aktuelle Modell im Kapitel \ref{eval:eval1} evaluiert, damit ein Vergleich mit dem neuen Modell möglich ist.
	
\subsection{Experiment 2}\label{model:ep2}
	
In diesem Experiment wird das Modell aus dem ersten Experiment übernommen und weiter verbessert. Das Ziel ist zunächst die Reduzierung der Differenz von $val\_accuracy$ und $accuracy$, damit das Modell genauere Ergebnisse liefern kann. Dafür wird die Dropout Schicht verwendet, welche die Daten eliminiert, die zu einer Überanpassung des Modells führen. In diesem Layer werden Datensatze die mit einer Häufigkeit von rate auftreten, auf 0 gesetzt. Dabei ist rate der Parameter von dem Dropout Layer und gibt die Häufigkeit der zu entfernenden Inputs an \cite{tensorflow2022}.\\

\begin{itemize}
	\item Convolutional Layer (Conv2D)
	\item Pooling Layer (MaxPooling2D)
	\item Dropout Layer (Dropout)
	\item Flatten Layer (Flatten)
	\item Fully-Connected Layer (Dense)
	\label{tab:model2}
\end{itemize}

\subsubsection{Trainingsphase}

\begin{figure}[h!]
	\centering
	\includegraphics[width=13.5cm, height=10cm]		{ExperimentModelTrainingsphase_2.png}
	\caption{ Bewertung Trainingsphase \cite{HK22}(Experiment 2)}
	\label{fig:fig16}
\end{figure}

Es wird deutlich, dass die Genauigkeit der Trainingsdaten, mit der Genauigkeit der Validierungsdaten fast übereinstimmt. Durch das Hinzufügen der Dropout Schicht wird also eine Überanpassung an die Trainingsdaten verhindert, womit das Modell auf unbekannte Daten besser vorbereitet ist. Die Differenz der Genauigkeit $accuracy$ und $val\_accuracy$ wurde von $2\%$ auf  $0.38\%$ reduziert.
\begin{figure}[h!]
	\centering
	\includegraphics[width=10cm,height=8cm]		{ExperimentModelBewertungsgraf_2.png}
	\caption{ Bewertung Trainingsphase \cite{HK22}(Experiment 2)}
	\label{fig:fig28}
\end{figure}

Im diesem Schritt wurde das Modell so optimiert, dass die Überanpassung verhindert werden kann. Durch den Graphen im Abbild \ref{fig:fig28} ist ersichtlich, dass die Genauigkeiten der Validierungs- und Trainingsdaten konvergieren. Die großen Sprünge im Graphen wurden genauso beseitigt. Dazu ist die Differenz der Genauigkeiten von $2\%$ auf $0.38\%$ gesunken. Als nächstes wird das Modell mit den Testdaten getestet, was in Abschnitt \ref{eval:eval2} bearbeitet wird.

\subsection{Experiment 3}\label{model:ep3}

In diesem Modellierungsschritt wird der Fokus auf die Leistung der Prognosen gelegt. Es wurden bisher zwei Modelle erstellt, die bezüglich der Leistung  fast identisch sind. In diesem Schritt ist das Ziel, die Leistung des Modells zu erhöhen. Dabei werden mehrere Schichten hinzugefügt oder geändert. Zunächst werden alle Conv2D Schichten verdoppelt, um mehrere Merkmale extrahieren zu können. Damit die verdoppelten Conv2D Schichten die Merkmale nicht verdoppelt an die nächste Schritt übergeben, wird der Dropout Parameter (rate) reduziert. Da unsere Conv2D Schichten verdoppelt wurden, muss zunächst der Fully-Connected-Layer vergrößert werden. Als Parameter wird in dieser Schicht die Neuronen-Anzahl drastisch erhöht.

\subsubsection{Trainingsphase}


\begin{figure}[h!]
	\centering
	\includegraphics[width=12cm,height=13.5cm]		{ExperimentModelTrainingsphase_3.png}
	\caption{ Bewertung Trainingsphase \cite{HK22}(Experiment 3)}
	\label{fig:fig31}
\end{figure}

Während der Trainingsphase erreicht das Modell eine Genauigkeit von maximal $95.31\%$ was eine Erhöhung der Leistung des Modells darstellt. Die Evaluierung mit den Testdaten erfolgt in Abschnitt \ref{eval:eval3}.

\section{Evaluation}\label{eval:eval}

Die definierten Modelle, werden nun im Evaluationsschritt getestet. Für das Testen wird hier der Testdatensatz eingesetzt.

\subsection{Evaluation Experiment 1}\label{eval:eval1}

Das Modell aus Experiment 1 wurde bisher trainiert und sollte als nächstes getestet werden. Hierzu werden dem Modell die Testdaten übergeben. Aus der Trainingsphase ist bekannt dass, das Modell eine Genauigkeit von $91\%$ hat. Bei der Evaluation wird für jede Klasse die Präzision und Trefferquote berechnet. Somit kann für jede Klasse eine Bewertung stattfinden.

\subsubsection{Testphase}

Aus den Daten im Abbild \ref{fig:fig18} kann die durchschnittliche Genauigkeit und der Verlust berechnet werden. Das aktuelle Modell erreicht eine durchschnittliche Genauigkeit von $91.96\%$ einen durchschnittlichen Verlust von $23.17\%$  über alle Klassen. \\

\begin{figure}[h!]
	\centering
	\includegraphics[width=10cm,height=8cm]		{ExperimenteEval1.png}
	\caption{ Bewertung Testphase \cite{HK22}(Experiment 3)}
	\label{fig:fig18}
\end{figure}

Das Modell erzielt für jede Klasse eine unterschiedliche Präzision und Trefferquote. Dabei werden die Klassen, wie zum Beispiel Bag, Sandal, Ankle Boot, Dress, Sneaker und Trouser mit einer Präzision von $95\%$ bis $99\%$ prognostiziert. Die Trefferquoten zu diesen Klassen liegen im Bereich von $92\%$ bis $98\%$. Somit erreicht das Modell für diese Klassen eine gute Leistung. Als nächstes werden die Klassen ausgewählt, für die eine schlechte Leistung in dem aktuellen Modell erbracht wurde. Die Klassen Shirt, Coat und Top haben eine Präzision von $83\%$ bis $86\%$ und deren Trefferquote liegt zwischen $69\%$ bis $92\%$. Dabei hat die Klasse Coat eine höhere Trefferquote ($92\%$)  als seine Präzision ($86\%$). Aufgrund der Überanpassung im Modell, welche durch die Trainingsphase entdeckt wurde, muss zunächst das Modell im nächsten Schritt \ref{model:ep2} optimiert werden.

\subsection{Evaluation Experiment 2}\label{eval:eval2}

Bisher wurde das zweite Experiment erstellt und es sollten durch die Anwendung der Dropout Schicht keine Überanpassungen mehr stattfinden. Mit diesem Schritt wird das optimierte Modell neu getestet, um Änderungen bei den Metriken zu erkennen.
\subsubsection{Testphase}

\begin{figure}[h!]
	\centering
	\includegraphics[width=10cm,height=7cm]		{ExperimenteEval1und2Vergleich.png}
	\caption{ Bewertung Testphase mit Vergleichswerten aus dem Experiment 1 \cite{HK22}(Experiment 2)}
	\label{fig:fig30}
\end{figure}

Im Abbild \ref{fig:fig30} sind die Lösungen des optimierten Modells mit den Werten von dem zuvor erstellten Modell zu sehen. Die Ergebnisse aus dem letzten Modell wurden nur dann übertragen, wenn es auch eine Änderung gegeben hat. So ist ersichtlicher, was im Modell wirklich optimiert wurde und was nicht. Eine Änderung der Leistungen des Modells wird deutlich durch die Abbildung \ref{fig:fig30}. Die zuvor im Evaluationsschritt ausgewählten Klassen, für die gute Ergebnisse erzielt wurden, werden zunächst im aktuellen Modell betrachtet und verglichen. Um diese einfacher zu beschreiben, werden die Differenzen der einzelnen Leistungen aufgelistet.\\

\begin{table}[h!]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Klasse & Differenz Präzision & Differenz Trefferquote \\
			\hline
			Top  & 0 & 0\\
			\hline
			Trouser  & 0 & +1\%  \\
			\hline
			Pullover   & -1\% & +1\% \\
			\hline
			Dress   & +2\% & -2\% \\
			\hline
			Coat   & +3\% & -8\% \\
			\hline
			Sandal & +1\% & -1\% \\
			\hline
			Shirt & -2\% & +1\% \\
			\hline
			Sneaker & +1\% & -1\% \\
			\hline
			Bag & 0 & 0 \\
			\hline
			Ankle boot & -3\% & +1\% \\
			\hline
		\end{tabular}
		\caption{Differenz neue und alte Ergebnisse für Experiment 2}
		\label{tab:differenz}
	\end{center}
\end{table}

Durch die Tabelle \ref{tab:differenz} werden die Ergebnisse deutlicher beschrieben. Da dieses Modell nur die Überanpassung bearbeitet hat, ist auch demnach keine Verbesserung des Modells ersichtlich. Die Trefferquoten wurden bei den Klassen Trouser, Shirt und Pullover um $1\%$ verbessert. Die Vorhersage für die Klassen Coat und Dress haben sich im Gegenzug verschlechtert. Da das Modell bisher nicht optimiert wurde, wäre die Empfehlung in diesem Fall, den Sprung zur Modellierung \ref{model:ep3} zurück zu machen. 

\subsection{Evaluation Experiment 3}\label{eval:eval3}

Durch das dritte Experiment wurde das Modell noch einmal optimiert. Dies wird in den nächsten Schritten näher betrachtet und es wird ein Vergleich zum alten Modell anhand einer Tabelle erstellt, die die Differenz der Ergebnisse darstellt. Die durchschnittliche Genauigkeit beträgt für dieses Modell $92.97\%$ und der durchschnittlicher Verlust $21.09\%$.

\begin{figure}[h!]
	\centering
	\includegraphics[width=10cm,height=7cm]		{ExperimenteEval2und3Vergleich.png}
	\caption{ Bewertung Testphase \cite{HK22}(Experiment 3)}
	\label{fig:fig20}
\end{figure}

Im Abbild \ref{fig:fig20} werden die Klassen mit den erzielten Ergebnissen aus dem letzten Modell und den Ergebnissen aus dem aktuellen Modell dargestellt. Wenn die Ergebnisse des letzten Modells nicht aufgeführt sind, bedeutet das, dass die Leistung der Vorhersagen sich für diese Klassen nicht verändert hat. Im nächsten Schritt werden diese Änderungen im Detail betrachtet, indem die Differenz der Ergebnisse berechnet und in einer Tabelle dargestellt wird. Ein Beispiel dazu zeigt die folgende Tabelle \ref{tab:differenz2}.

\begin{table}[h!]
	\begin{center}
		\begin{tabular}{|c|c|c|}
			\hline
			Klasse & Differenz Präzision & Differenz Trefferquote \\
			\hline
			Top  & +3\% & 0\\
			\hline
			Trouser  & +1\% & +1\%  \\
			\hline
			Pullover   & 0 & +3\% \\
			\hline
			Dress   & 0 & +2\% \\
			\hline
			Coat   & -4\% & +10\% \\
			\hline
			Sandal & +1\% & -1\% \\
			\hline
			Shirt & +4\% & +1\% \\
			\hline
			Sneaker & +1\% & +1\% \\
			\hline
			Bag & 0 & 0 \\
			\hline
			Ankle boot & +2\% & +1\% \\
			\hline
		\end{tabular}
		\caption{Differenz neue und alte Ergebnisse für Experiment 2}
		\label{tab:differenz2}
	\end{center}
\end{table}

- positive änderungen 

- was sagen die trefferquoten gesamt aus und wie gut schneidet es i, vergleich zum alten modell

-sind diese ergebnisse das Ziel das Projekts


\section{Deployment}\label{dp:dp}

Damit die implementierten Modelle den Zielgruppen zur Verfügung gestellt werden können, kann man zum Beispiel das Modell aus dem dritten Experiment cloud-basiert als Service bereitstellen. Eine mögliche Zielgruppe ist vor allem der Bereich Online-Retail. Dazu könnte für die Verwendung des Services, durch die Mitarbeiter eines Unternehmens, eine Benutzeroberfläche erstellt werden um dann eigene Bilddaten zu importieren und danach an den Service weiterzugeben. Dies könnte zum Beispiel bei der automatischen Generierung von Bildbeschreibungen unterstützen. Ein weiterer möglicher Anwendungsfall wäre, wenn die Bilddaten aus einem Kamerasensor stammen und diese durch den Service automatisch klassifiziert werden. Diese Klassifizierung kann dann, wie anfangs in der Problemstellung beschrieben, bei Retouren das automatische Labeln der Waren ermöglichen. 

\newpage
\chapter{Zusammenfassung und Ausblick}

- zusammenfassung und vergleich aus ein model im internet






- ausblick zu verbesserung und nutzbarkeit des Modells




















\cleardoubleoddpage

\addcontentsline{toc}{chapter}{Literaturverzeichnis}
\bibliography{Literatur}
\bibliographystyle{alpha}

\cleardoublepage
	
\end{document}